# Default model to use
model = "gpt-5-codex"

# Model provider (e.g., "openai", "azure")
model_provider = "openai"

# Approval policy for executing commands
# Options: "untrusted", "on-failure", "on-request", "never"
approval_policy = "on-request"

# Sandbox execution mode
# Options: "read-only", "workspace-write", "danger-full-access"
sandbox_mode = "workspace-write"
# BEGIN MCP servers (managed by Ansible)

[mcp_servers]
[mcp_servers.arxiv-mcp-server]
type = "stdio"
command = "uvx"
args = [
  "arxiv-mcp-server",
  "--storage-path",
  "/path/to/papers"
]

[mcp_servers.context7]
type = "stdio"
command = "npx"
args = [
  "-y",
  "@upstash/context7-mcp@latest"
]

[mcp_servers.markitdown]
type = "stdio"
command = "uvx"
args = [
  "markitdown-mcp"
]

[mcp_servers.playwright]
type = "stdio"
command = "npx"
args = [
  "-y",
  "@playwright/mcp@latest"
]

[mcp_servers.sequentialthinking]
type = "stdio"
command = "docker"
args = [
  "run",
  "--rm",
  "-i",
  "mcp/sequentialthinking"
]

[mcp_servers.serena]
type = "stdio"
command = "uvx"
args = [
  "--from",
  "git+https://github.com/oraios/serena",
  "serena",
  "start-mcp-server",
  "--context",
  "ide-assistant",
  "--enable-web-dashboard",
  "false",
  "--enable-gui-log-window",
  "false",
  "--log-level",
  "CRITICAL"
]

[mcp_servers.voicevox]
type = "stdio"
command = "npx"
args = [
  "-y",
  "@t09tanaka/mcp-simple-voicevox"
]

[mcp_servers.youtube]
type = "stdio"
command = "npx"
args = [
  "-y",
  "@anaisbetts/mcp-youtube"
]

# END MCP servers (managed by Ansible)
